{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns=None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from dateutil.rrule import *\n",
    "from datetime import datetime as dt\n",
    "\n",
    "%config InteractiveShell.ast_node_interactivity = 'all'\n",
    "#import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"C:/Users/Ariel/Desktop/tp taxi 2/Proyecto-Taxis-NYC/yellow_t_2018-01.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos un correcto formato de data a cada columna para su optimizacion e ingesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_datime(df):\n",
    "    df[\"dayofmonth\"] = df['tpep_pickup_datetime'].apply(pd.to_datetime).dt.day\n",
    "    df[\"hora\"]= df.tpep_pickup_datetime.dt.floor(\"H\")\n",
    "\n",
    "    df.drop(columns=[\"congestion_surcharge\",\"airport_fee\",\"store_and_fwd_flag\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "def t_int(df):\n",
    "    df['passenger_count'] = pd.to_numeric(df['passenger_count'], downcast=\"integer\" )\n",
    "    df['RatecodeID'] = pd.to_numeric(df['RatecodeID'], downcast=\"integer\" )\n",
    "    df['PULocationID'] = pd.to_numeric(df['PULocationID'], downcast=\"integer\" )\n",
    "    df['DOLocationID'] = pd.to_numeric(df['DOLocationID'], downcast=\"integer\" )\n",
    "    df['payment_type'] = pd.to_numeric(df['payment_type'], downcast=\"integer\" )\n",
    "    df['RatecodeID'] = pd.to_numeric(df['RatecodeID'], downcast=\"integer\" )\n",
    "    df['RatecodeID'] = pd.to_numeric(df['RatecodeID'], downcast=\"integer\" )\n",
    "    return df\n",
    "\n",
    "def t_float(df):\n",
    "    df['trip_distance'] = pd.to_numeric(df['trip_distance'], downcast=\"float\" )\n",
    "    df['fare_amount'] = pd.to_numeric(df['fare_amount'], downcast=\"float\" )\n",
    "    df['extra'] = pd.to_numeric(df['extra'], downcast=\"float\" )\n",
    "    df['mta_tax'] = pd.to_numeric(df['mta_tax'], downcast=\"float\" )\n",
    "    df['tip_amount'] = pd.to_numeric(df['tip_amount'], downcast=\"float\" )\n",
    "    df['tolls_amount'] = pd.to_numeric(df['tolls_amount'], downcast=\"float\" )\n",
    "    df['improvement_surcharge'] = pd.to_numeric(df['improvement_surcharge'], downcast=\"float\" )\n",
    "    df['total_amount'] = pd.to_numeric(round(df['total_amount'] ))\n",
    "    return df\n",
    "\n",
    "def total_transform(df):\n",
    "    df = t_datime(df)\n",
    "    df = t_int(df)\n",
    "    df = t_float(df)\n",
    "    return df\n",
    "\n",
    "df =  total_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos un dia del df para poder trabajarlo en esta etapa preeliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Impar = df[df.dayofmonth  == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro de fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted(df):\n",
    "    global bol\n",
    "    bol = 1\n",
    "    df.sort_values(by='tpep_pickup_datetime', ascending=True, inplace=True)\n",
    "    df = df[df[\"tpep_pickup_datetime\"] >= '2018-01-01 00:00:00']\n",
    "    if bol == 1:\n",
    "        df = df[df[\"tpep_pickup_datetime\"] <= '2018-02-01 00:00:00']\n",
    "        bol = 0\n",
    "    return df\n",
    "\n",
    "df_Impar = sorted(df_Impar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombramos los Borough con las locationsID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boroughs (df_Impar):\n",
    "    #se carga el csv con las zonas\n",
    "    zona = pd.read_csv(\"C:/Users/Ariel/Desktop/tp taxi 2/Proyecto-Taxis-NYC/taxi+_zone_lookup.csv\")\n",
    "    #se borran las columnas que no usamos\n",
    "    zona.drop(columns=[\"Zone\",\"service_zone\"], inplace=True)\n",
    "    #cambiamos el nombre para poder hacer el merge\n",
    "    zona.rename(columns={\"LocationID\": \"PULocationID\"},inplace=True)\n",
    "    #se hace el merge y se crea la columnna resultante del merge \"Borough\"\n",
    "    df_Impar = pd.merge(df_Impar,zona, how=\"left\", on=[\"PULocationID\"])\n",
    "    #se le cambia el nombre a \"boroug\" para que haga referencia al borough de partida\n",
    "    df_Impar.rename(columns={\"Borough\": \"PUBorough\"},inplace=True)\n",
    "    #mismo procedimiento para borough de llegada\n",
    "    zona.rename(columns={\"PULocationID\": \"DOLocationID\"},inplace=True)\n",
    "    df_Impar = pd.merge(df_Impar,zona, how=\"left\", on=[\"DOLocationID\"])\n",
    "    df_Impar.rename(columns={\"Borough\": \"DOLocation\"},inplace=True)\n",
    "    return df_Impar\n",
    "\n",
    "df_Impar = boroughs(df_Impar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creacion del dataframe de clima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documentacion mismo nombre del clima en cada update\n",
    "\n",
    "clima = pd.read_csv(\"C:/Users/Ariel/Desktop/tp taxi 2/Proyecto-Taxis-NYC/clima.csv\")\n",
    "clima.drop(columns=[\"name\",\"dew\",\"humidity\",\"precipprob\",\"preciptype\",\"severerisk\",\"uvindex\",\"icon\",\"stations\"], inplace=True)\n",
    "clima.drop(columns=[\"windgust\",\"windspeed\",\"winddir\",\"sealevelpressure\",\"cloudcover\",\"visibility\",\"solarradiation\",\"solarenergy\"], inplace=True)\n",
    "clima[\"datetime\"]=[x.replace('T',\" \") for x in clima[\"datetime\"]]\n",
    "clima.datetime = clima['datetime'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformacion de los datos para mejor optimizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_clima():\n",
    "    clima['temp'] = pd.to_numeric(clima['temp'], downcast=\"float\" )\n",
    "    clima['feelslike'] = pd.to_numeric(round(clima['feelslike'] ))\n",
    "    clima['precip'] = pd.to_numeric(clima['precip'], downcast=\"float\" )\n",
    "    clima['snow'] = pd.to_numeric(clima['snow'], downcast=\"float\" )\n",
    "    clima['snowdepth'] = pd.to_numeric(clima['snowdepth'], downcast=\"float\" )\n",
    "    clima[\"conditions\"]=clima[\"conditions\"].astype(str)\n",
    "    return clima\n",
    "\n",
    "clima = t_clima()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se filtra el clima mes por mes para la ingesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_clima(dat,clima):\n",
    "    clima.sort_values(by='datetime', ascending=True, inplace=True)\n",
    "    date = dat\n",
    "    if (clima[\"datetime\"] >= date).any():\n",
    "        clima = clima[clima[\"datetime\"] >= date]\n",
    "        date_next= date + relativedelta(months=+1)\n",
    "        clima = clima[clima[\"datetime\"] <= date_next]\n",
    "        return clima\n",
    "    else:\n",
    "        date+= relativedelta(months=+1)\n",
    "        return control_clima(dat)\n",
    "\n",
    "clima = control_clima(dt(2018,1,1),clima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el nombre de la columna para la conexion con la primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clima in global\n",
    "\n",
    "def aux ():\n",
    "    clima.rename(columns={\"datetime\": \"hora\"},inplace=True)\n",
    "    return clima\n",
    "\n",
    "clima = aux()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Impar = pd.merge(df_Impar,clima, how=\"left\", on=[\"hora\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropeamos valores menores a 0 y los ratecodeID 6 y 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_values(df_Impar):   \n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.fare_amount<0].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.trip_distance<0].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.total_amount<0].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.RatecodeID==6].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.RatecodeID==99].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.trip_distance==0].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.fare_amount==0].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.total_amount==0].index)\n",
    "    return df_Impar\n",
    "\n",
    "df_Impar=neg_values(df_Impar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamiento de los outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def t_outliers(column):\n",
    "    Q1 = df_Impar[column].quantile(0.01)\n",
    "    Q3 = df_Impar[column].quantile(0.99)\n",
    "    #Se calcula el rango intercuartilico IQR.\n",
    "    IQR = Q3 -Q1\n",
    "    outliers_Sup_trip = (Q3 + (1.5*IQR)) \n",
    "    #se crea la columna marcador\n",
    "    df_Impar[\"trip_distance_out\"] = df_Impar.apply(lambda row: 1 if row[column]>outliers_Sup_trip else 0, axis=1)\n",
    "    return df_Impar\n",
    "\n",
    "def total_outliers():\n",
    "    df_Impar=t_outliers(\"trip_distance\")\n",
    "    df_Impar=t_outliers(\"fare_amount\")\n",
    "    df_Impar=t_outliers(\"tip_amount\")\n",
    "    df_Impar=t_outliers(\"total_amount\")\n",
    "    return df_Impar\n",
    "\n",
    "df_Impar=total_outliers()\n",
    "\n",
    "\n",
    "df_Impar[\"outlier\"] = df_Impar.apply(lambda row: 1 if row[\"trip_distance_out\"]==1 or row[\"fare_amount_out\"]==1 or\n",
    "row[\"total_amount_out\"]==1 or row[\"tip_amount_out\"]==1 else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Impar.to_parquet('',engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Impar = pd.read_parquet(\"C:/Users/andre/OneDrive/Escritorio/proyecto final 3/Proyecto-Taxis-NYC/data/df_Impar_marcado.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrancamos con SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as msql\n",
    "from mysql.connector import Error\n",
    "from sqlalchemy import create_engine\n",
    "from multiprocessing import connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df total de los taxis\n",
    "#df = pd.read_parquet(\"C:/Users/andre/OneDrive/Escritorio/proyecto final 3/Proyecto-Taxis-NYC/data/df_Impar_marcado.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_Impar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df.dayofmonth == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buscar los df ya tratados\n",
    "df_Zona = pd.read_csv(\"C:/Users/Ariel/Desktop/tp taxi 2/Proyecto-Taxis-NYC/taxi+_zone_lookup.csv\", sep=\",\")\n",
    "#df_Clima=pd.read_csv(\"Proyecto-Taxis-NYC/clima.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos conectamos a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database is created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    conn = msql.connect(host='127.0.0.1', user='root',  \n",
    "                        password='root')#give ur username, password\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"CREATE DATABASE IF NOT EXISTS taxi_1;\")\n",
    "        print(\"Database is created\")\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name,db_name, u_name, u_pass, port_num  = \"127.0.0.1\",\"taxi_1\", \"root\", \"root\", \"3306\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'mysql' is not defined\n"
     ]
    }
   ],
   "source": [
    "'''try:\n",
    "    connection = msql.connector.connect(\n",
    "    host= host_name,\n",
    "    user= u_name,\n",
    "    password= u_pass,\n",
    "    database= db_name\n",
    "    )\n",
    "  \n",
    "    if connection.is_connected():\n",
    "        print('Conexion exitosa')\n",
    "        info_server = connection.get_server_info()\n",
    "        print(info_server)\n",
    "except Exception as ex:\n",
    "    print(ex)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creacion del motor de base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engine = create_engine(\"mysql+mysqlconnector://\" + u_name + \":\" + u_pass + \"@\" \n",
    "                        + host_name + \":\" + port_num + \"/\" + db_name, echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importacion del dataframe a nuestra base de datos en SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1327"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#CAMBIAR LOS NOMBRES DEL DF QUE QUEREMOS CARGAR Y EL NOMBRE QUE QUEREMOS QUE TENGA LA TABLA EN SQL\n",
    "df.to_sql(name=\"taxis\", con=engine, chunksize=200, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Zona.to_sql(name=\"zona\", con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clima.to_sql(name=\"clima\", con=engine, if_exists=\"append\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39a4a283ba33cbf7914bca7cedace0796cf5d1a50a73c1cda853b36322d337e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
