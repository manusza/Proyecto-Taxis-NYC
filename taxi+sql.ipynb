{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns=None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from dateutil.rrule import *\n",
    "from datetime import datetime as dt\n",
    "\n",
    "%config InteractiveShell.ast_node_interactivity = 'all'\n",
    "#import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../Proyecto-Taxis-NYC/data/yellow_t_2018-01.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_datime(df):\n",
    "    df[\"dayofmonth\"] = df['tpep_pickup_datetime'].apply(pd.to_datetime).dt.day\n",
    "    df[\"hora\"]= df.tpep_pickup_datetime.dt.floor(\"H\")\n",
    "\n",
    "    df.drop(columns=[\"congestion_surcharge\",\"airport_fee\",\"store_and_fwd_flag\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "def t_int(df):\n",
    "    df['passenger_count'] = pd.to_numeric(df['passenger_count'], downcast=\"integer\" )\n",
    "    df['RatecodeID'] = pd.to_numeric(df['RatecodeID'], downcast=\"integer\" )\n",
    "    df['PULocationID'] = pd.to_numeric(df['PULocationID'], downcast=\"integer\" )\n",
    "    df['DOLocationID'] = pd.to_numeric(df['DOLocationID'], downcast=\"integer\" )\n",
    "    df['payment_type'] = pd.to_numeric(df['payment_type'], downcast=\"integer\" )\n",
    "    df['RatecodeID'] = pd.to_numeric(df['RatecodeID'], downcast=\"integer\" )\n",
    "    df['RatecodeID'] = pd.to_numeric(df['RatecodeID'], downcast=\"integer\" )\n",
    "    return df\n",
    "\n",
    "def t_float(df):\n",
    "    df['trip_distance'] = pd.to_numeric(df['trip_distance'], downcast=\"float\" )\n",
    "    df['fare_amount'] = pd.to_numeric(df['fare_amount'], downcast=\"float\" )\n",
    "    df['extra'] = pd.to_numeric(df['extra'], downcast=\"float\" )\n",
    "    df['mta_tax'] = pd.to_numeric(df['mta_tax'], downcast=\"float\" )\n",
    "    df['tip_amount'] = pd.to_numeric(df['tip_amount'], downcast=\"float\" )\n",
    "    df['tolls_amount'] = pd.to_numeric(df['tolls_amount'], downcast=\"float\" )\n",
    "    df['improvement_surcharge'] = pd.to_numeric(df['improvement_surcharge'], downcast=\"float\" )\n",
    "    df['total_amount'] = pd.to_numeric(round(df['total_amount'] ))\n",
    "    return df\n",
    "\n",
    "def total_transform(df):\n",
    "    df = t_datime(df)\n",
    "    df = t_int(df)\n",
    "    df = t_float(df)\n",
    "    return df\n",
    "\n",
    "df =  total_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Impar = df[df.dayofmonth  == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted(df):\n",
    "    global bol\n",
    "    bol = 1\n",
    "    df.sort_values(by='tpep_pickup_datetime', ascending=True, inplace=True)\n",
    "    df = df[df[\"tpep_pickup_datetime\"] >= '2018-01-01 00:00:00']\n",
    "    if bol == 1:\n",
    "        df = df[df[\"tpep_pickup_datetime\"] <= '2018-02-01 00:00:00']\n",
    "        bol = 0\n",
    "    return df\n",
    "\n",
    "df_Impar = sorted(df_Impar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boroughs (df_Impar):\n",
    "    #se carga el csv con las zonas\n",
    "    zona = pd.read_csv(\"taxi+_zone_lookup.csv\")\n",
    "    #se borran las columnas que no usamos\n",
    "    zona.drop(columns=[\"Zone\",\"service_zone\"], inplace=True)\n",
    "    #cambiamos el nombre para poder hacer el merge\n",
    "    zona.rename(columns={\"LocationID\": \"PULocationID\"},inplace=True)\n",
    "    #se hace el merge y se crea la columnna resultante del merge \"Borough\"\n",
    "    df_Impar = pd.merge(df_Impar,zona, how=\"left\", on=[\"PULocationID\"])\n",
    "    #se le cambia el nombre a \"boroug\" para que haga referencia al borough de partida\n",
    "    df_Impar.rename(columns={\"Borough\": \"PUBorough\"},inplace=True)\n",
    "    #mismo procedimiento para borough de llegada\n",
    "    zona.rename(columns={\"PULocationID\": \"DOLocationID\"},inplace=True)\n",
    "    df_Impar = pd.merge(df_Impar,zona, how=\"left\", on=[\"DOLocationID\"])\n",
    "    df_Impar.rename(columns={\"Borough\": \"DOLocation\"},inplace=True)\n",
    "    return df_Impar\n",
    "\n",
    "df_Impar = boroughs(df_Impar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documentacion mismo nombre del clima en cada update\n",
    "\n",
    "clima = pd.read_csv(\"C:/Users/andre/OneDrive/Escritorio/proyecto final 3/Proyecto-Taxis-NYC/clima.csv\")\n",
    "clima.drop(columns=[\"name\",\"dew\",\"humidity\",\"precipprob\",\"preciptype\",\"severerisk\",\"uvindex\",\"icon\",\"stations\"], inplace=True)\n",
    "clima.drop(columns=[\"windgust\",\"windspeed\",\"winddir\",\"sealevelpressure\",\"cloudcover\",\"visibility\",\"solarradiation\",\"solarenergy\"], inplace=True)\n",
    "clima[\"datetime\"]=[x.replace('T',\" \") for x in clima[\"datetime\"]]\n",
    "clima.datetime = clima['datetime'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_clima():\n",
    "    clima['temp'] = pd.to_numeric(clima['temp'], downcast=\"float\" )\n",
    "    clima['feelslike'] = pd.to_numeric(round(clima['feelslike'] ))\n",
    "    clima['precip'] = pd.to_numeric(clima['precip'], downcast=\"float\" )\n",
    "    clima['snow'] = pd.to_numeric(clima['snow'], downcast=\"float\" )\n",
    "    clima['snowdepth'] = pd.to_numeric(clima['snowdepth'], downcast=\"float\" )\n",
    "    clima[\"conditions\"]=clima[\"conditions\"].astype(str)\n",
    "    return clima\n",
    "\n",
    "clima = t_clima()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_clima(dat,clima):\n",
    "    #aplicar sort fecha\n",
    "    clima.sort_values(by='datetime', ascending=True, inplace=True)\n",
    "    date = dat\n",
    "    if (clima[\"datetime\"] >= date).any():\n",
    "        clima = clima[clima[\"datetime\"] >= date]\n",
    "        date_next= date + relativedelta(months=+1)\n",
    "        clima = clima[clima[\"datetime\"] <= date_next]\n",
    "        return clima\n",
    "    else:\n",
    "        date+= relativedelta(months=+1)\n",
    "        return control_clima(dat)\n",
    "\n",
    "clima = control_clima(dt(2018,1,1),clima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clima in global\n",
    "\n",
    "def aux ():\n",
    "    \n",
    "    clima.rename(columns={\"datetime\": \"hora\"},inplace=True)\n",
    "    return clima\n",
    "\n",
    "clima = aux()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Impar = pd.merge(df_Impar,clima, how=\"left\", on=[\"hora\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_values(df_Impar):   \n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.fare_amount<0].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.trip_distance<0].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.total_amount<0].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.RatecodeID==6].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.trip_distance==0].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.fare_amount==0].index)\n",
    "    df_Impar = df_Impar.drop(df_Impar[df_Impar.total_amount==0].index)\n",
    "    return df_Impar\n",
    "\n",
    "df_Impar=neg_values(df_Impar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratamiento de Outliers columna trip_distance\n",
    "Q1 = df_Impar[\"trip_distance\"].quantile(0.01)\n",
    "Q3 = df_Impar[\"trip_distance\"].quantile(0.99)\n",
    "#Se calcula el rango intercuartilico IQR.\n",
    "IQR = Q3 -Q1\n",
    "outliers_Sup_trip = (Q3 + (1.5*IQR)) \n",
    "#se crea la columna marcador\n",
    "df_Impar[\"trip_distance_out\"] = df_Impar.apply(lambda row: 1 if row[\"trip_distance\"]>outliers_Sup_trip else 0, axis=1)\n",
    "\n",
    "#se marco trip distance, ahora vamos por fare amount\n",
    "\n",
    "#Tratamiento de Outliers columna fare_amount\n",
    "Q1 = df_Impar[\"fare_amount\"].quantile(0.01)\n",
    "Q3 = df_Impar[\"fare_amount\"].quantile(0.99)\n",
    "#Se calcula el rango intercuartilico IQR.\n",
    "IQR = Q3 -Q1\n",
    "outliers_Sup_fare = (Q3 + (1.5*IQR)) \n",
    "#se marco fare amount\n",
    "df_Impar[\"fare_amount_out\"] = df_Impar.apply(lambda row: 1 if row[\"fare_amount\"]>outliers_Sup_fare else 0, axis=1)\n",
    "\n",
    "#Tratamiento de Outliers columna tip_amount\n",
    "Q1 = df_Impar[\"tip_amount\"].quantile(0.01)\n",
    "Q3 = df_Impar[\"tip_amount\"].quantile(0.99)\n",
    "#Se calcula el rango intercuartilico IQR.\n",
    "IQR = Q3 -Q1\n",
    "outliers_Sup_tip = (Q3 + (1.5*IQR)) \n",
    "df_Impar[\"tip_amount_out\"] = df_Impar.apply(lambda row: 1 if row[\"tip_amount\"]>outliers_Sup_tip else 0, axis=1)\n",
    "\n",
    "#se marco tip amount, ahora le toca a total amount\n",
    "\n",
    "#Tratamiento de Outliers columna total_amount\n",
    "Q1 = df_Impar[\"total_amount\"].quantile(0.01)\n",
    "Q3 = df_Impar[\"total_amount\"].quantile(0.99)\n",
    "#Se calcula el rango intercuartilico IQR.\n",
    "IQR = Q3 -Q1\n",
    "outliers_Sup_total_a = (Q3 + (1.5*IQR)) \n",
    "df_Impar[\"total_amount_out\"] = df_Impar.apply(lambda row: 1 if row[\"tip_amount\"]>outliers_Sup_total_a else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Impar[\"outlier\"] = df_Impar.apply(lambda row: 1 if row[\"trip_distance_out\"]==1 or row[\"fare_amount_out\"]==1 or\n",
    "row[\"total_amount_out\"]==1 or row[\"tip_amount_out\"]==1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Impar.to_parquet('C:/Users/andre/OneDrive/Escritorio/proyecto final 3/Proyecto-Taxis-NYC/data/df_Impar_marcado.parquet',engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Impar = pd.read_parquet(\"C:/Users/andre/OneDrive/Escritorio/proyecto final 3/Proyecto-Taxis-NYC/data/df_Impar_marcado.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrancamos con SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as msql\n",
    "from mysql.connector import Error\n",
    "from sqlalchemy import create_engine\n",
    "from multiprocessing import connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df total de los taxis\n",
    "df = pd.read_parquet(\"C:/Users/andre/OneDrive/Escritorio/proyecto final 3/Proyecto-Taxis-NYC/data/df_Impar_marcado.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.dayofmonth == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buscar los df ya tratados\n",
    "df_Zona = pd.read_csv(\"taxi+_zone_lookup.csv\", sep=\",\")\n",
    "#df_Clima=pd.read_csv(\"Proyecto-Taxis-NYC/clima.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database is created\n"
     ]
    }
   ],
   "source": [
    "#CREA BASE DE DATOS\n",
    "try:\n",
    "    conn = msql.connect(host='127.0.0.1', user='root',  \n",
    "                        password='Andres1')#give ur username, password\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"CREATE DATABASE IF NOT EXISTS taxi_1;\")\n",
    "        print(\"Database is created\")\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name,db_name, u_name, u_pass, port_num  = \"127.0.0.1\",\"taxi_1\", \"root\", \"Andres1\", \"3306\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'mysql' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    connection = mysql.connector.connect(\n",
    "    host= host_name,\n",
    "    user= u_name,\n",
    "    password= u_pass,\n",
    "    database= db_name\n",
    "    )\n",
    "  \n",
    "    if connection.is_connected():\n",
    "        print('Conexion exitosa')\n",
    "        info_server = connection.get_server_info()\n",
    "        print(info_server)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion del motor de base de datos\n",
    "engine = create_engine(\"mysql+mysqlconnector://\" + u_name + \":\" + u_pass + \"@\" \n",
    "                        + host_name + \":\" + port_num + \"/\" + db_name, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importacion del dataframe a nuestra base de datos en SQL \n",
    "#CAMBIAR LOS NOMBRES DEL DF QUE QUEREMOS CARGAR Y EL NOMBRE QUE QUEREMOS QUE TENGA LA TABLA EN SQL\n",
    "#df.to_sql(name=\"taxis\", con=engine, chunksize=200, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Zona.to_sql(name=\"zona\", con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clima.to_sql(name=\"clima\", con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creacion de tablas para sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creacion Clima_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clima_conditions = clima.conditions.unique()\n",
    "Clima_conditions = pd.DataFrame(Clima_conditions)\n",
    "Clima_conditions[\"conditions\"] = Clima_conditions\n",
    "Clima_conditions = Clima_conditions.drop(columns=0)\n",
    "Clima_conditions.reset_index(inplace=True)\n",
    "Clima_conditions.rename(columns={\"index\":\"IdCondiciones\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clima_conditions.to_sql(name=\"clima_conditions\", con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creacion tabla Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Borough = pd.read_csv(\"Taxi+_zone_lookup.csv\", usecols=['Borough'])\n",
    "Borough = Borough.Borough.unique()\n",
    "Borough = pd.DataFrame(Borough)\n",
    "Borough[\"Borough\"] = Borough\n",
    "Borough = Borough.drop(columns=0)\n",
    "Borough.reset_index(inplace=True)\n",
    "Borough.rename(columns={\"index\":\"IdBorough\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Borough.to_sql(name=\"borough\", con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creacion tabla Vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vendor = df_Impar.VendorID.unique()\n",
    "Vendor = pd.DataFrame(Vendor)\n",
    "Vendor[\"VendorID\"] = Vendor\n",
    "Vendor = Vendor.drop(columns=0)\n",
    "Vendor[\"Vendor\"] = Vendor.VendorID\n",
    "Vendor.Vendor.replace(1,\"Tecnologías móviles creativas\", inplace=True)\n",
    "Vendor.Vendor.replace(2,\"VeriFone Inc.\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vendor.to_sql(name=\"vendor\", con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creacion tabla Ratecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "RatecodeID = df_Impar.RatecodeID.unique()\n",
    "RatecodeID = pd.DataFrame(RatecodeID)\n",
    "RatecodeID[\"RatecodeID\"] = RatecodeID\n",
    "RatecodeID = RatecodeID.drop(columns=0)\n",
    "RatecodeID[\"Ratecode\"] = RatecodeID.RatecodeID\n",
    "RatecodeID.Ratecode.replace(1,\"Tarifa estándar\", inplace=True)\n",
    "RatecodeID.Ratecode.replace(2,\"JFK\", inplace=True)\n",
    "RatecodeID.Ratecode.replace(3,\"Nueva York\", inplace=True)\n",
    "RatecodeID.Ratecode.replace(4,\"Nasáu o Westchester\", inplace=True)\n",
    "RatecodeID.Ratecode.replace(5,\"Tarifa negociada\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RatecodeID.to_sql(name=\"ratecode\", con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eliminacion de columnas redundantes de df_impar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tenemos que borrar PULocationID y DOLocationID y reemplazar PUBorough y DOLocation por sus ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Impar['PUBorough']=np.where(df_Impar['PUBorough']==\"EWR\",0,df_Impar['PUBorough'])\n",
    "df_Impar['PUBorough']=np.where(df_Impar['PUBorough']==\"Queens\",1,df_Impar['PUBorough'])\n",
    "df_Impar['PUBorough']=np.where(df_Impar['PUBorough']==\"Bronx\",2,df_Impar['PUBorough'])\n",
    "df_Impar['PUBorough']=np.where(df_Impar['PUBorough']==\"Manhattan\",3,df_Impar['PUBorough'])\n",
    "df_Impar['PUBorough']=np.where(df_Impar['PUBorough']==\"Staten Island\",4,df_Impar['PUBorough'])\n",
    "df_Impar['PUBorough']=np.where(df_Impar['PUBorough']==\"Brooklyn\",5,df_Impar['PUBorough'])\n",
    "df_Impar['PUBorough']=np.where(df_Impar['PUBorough']==\"Unknown\",6,df_Impar['PUBorough'])\n",
    "\n",
    "df_Impar.rename(columns={\"DOLocation\":\"DOBorough\"},inplace=True)\n",
    "df_Impar['DOBorough']=np.where(df_Impar['DOBorough']==\"EWR\",0,df_Impar['DOBorough'])\n",
    "df_Impar['DOBorough']=np.where(df_Impar['DOBorough']==\"Queens\",1,df_Impar['DOBorough'])\n",
    "df_Impar['DOBorough']=np.where(df_Impar['DOBorough']==\"Bronx\",2,df_Impar['DOBorough'])\n",
    "df_Impar['DOBorough']=np.where(df_Impar['DOBorough']==\"Manhattan\",3,df_Impar['DOBorough'])\n",
    "df_Impar['DOBorough']=np.where(df_Impar['DOBorough']==\"Staten Island\",4,df_Impar['DOBorough'])\n",
    "df_Impar['DOBorough']=np.where(df_Impar['DOBorough']==\"Brooklyn\",5,df_Impar['DOBorough'])\n",
    "df_Impar['DOBorough']=np.where(df_Impar['DOBorough']==\"Unknown\",6,df_Impar['DOBorough'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Impar.drop(columns={\"PULocationID\",\"DOLocationID\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265213"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Impar.to_sql(name=\"taxis\", con=engine, chunksize=200, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creacion de tabla PaymentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "PaymentType = df_Impar.payment_type.unique()\n",
    "PaymentType = pd.DataFrame(PaymentType)\n",
    "PaymentType[\"PaymentTypeID\"] = PaymentType\n",
    "PaymentType = PaymentType.drop(columns=0)\n",
    "PaymentType[\"Payment\"] = PaymentType.PaymentTypeID\n",
    "PaymentType.Payment.replace(1,\"tarjeta de crédito\", inplace=True)\n",
    "PaymentType.Payment.replace(2,\"Efectivo\", inplace=True)\n",
    "PaymentType.Payment.replace(3,\"Sin cargo\", inplace=True)\n",
    "PaymentType.Payment.replace(4,\"Disputa\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PaymentType.to_sql(name=\"payment_type\", con=engine, chunksize=200, if_exists=\"append\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6847c98a8f86b01c6a19c518cd2f366693b80566b266804d5ca763cbb223f52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
